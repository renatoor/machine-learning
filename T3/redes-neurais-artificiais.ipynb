{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "residential-rough",
   "metadata": {},
   "source": [
    "# Redes neurais artificiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "super-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetBinaryClassifier, NeuralNetClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-spyware",
   "metadata": {},
   "source": [
    "## Redes MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capable-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credtrain.txt', sep='\\t', header=None)\n",
    "data_test = pd.read_csv('data/credtest.txt', sep='\\t', header=None)\n",
    "\n",
    "X = np.array(data.iloc[:, :-1]).astype(np.float32)\n",
    "y = np.array(data.iloc[:, -1]).astype(np.float32)\n",
    "\n",
    "X_test = np.array(data_test.iloc[:, :-1]).astype(np.float32)\n",
    "y_test = np.array(data_test.iloc[:, -1])\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_norm = ss.fit_transform(X)\n",
    "X_test_norm = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minute-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       352\n",
      "           1       0.80      0.97      0.88       225\n",
      "\n",
      "    accuracy                           0.90       577\n",
      "   macro avg       0.89      0.91      0.89       577\n",
      "weighted avg       0.91      0.90      0.90       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(11, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = NeuralNetBinaryClassifier(Net, max_epochs=200, lr=0.01, criterion=torch.nn.BCEWithLogitsLoss, verbose=0)\n",
    "net.fit(X_norm, y)\n",
    "y_predict = net.predict(X_test_norm)\n",
    "print(classification_report(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-contamination",
   "metadata": {},
   "source": [
    "## Redes convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-lyric",
   "metadata": {},
   "source": [
    "### MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extraordinary-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('data/train_catvnoncat.h5', 'r' )\n",
    "    train_set_x_orig = np.array(train_dataset['train_set_x'][:]).astype(np.float32) #your train set features\n",
    "    train_set_y_orig = np.array(train_dataset['train_set_y'][:]) #your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('data/test_catvnoncat.h5', 'r' )\n",
    "    test_set_x_orig = np.array(test_dataset['test_set_x'][:]).astype(np.float32) #your test set features\n",
    "    test_set_y_orig = np.array(test_dataset['test_set_y'][:]) #your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset['list_classes'][:]) #the list of classes\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "X_train, y_train, X_test, y_test, classes = load_dataset()\n",
    "\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1) / 255\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "proper-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58        21\n",
      "           1       0.70      0.79      0.74        29\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.67      0.66      0.66        50\n",
      "weighted avg       0.68      0.68      0.67        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NetSoftmax(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetSoftmax, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(64 * 64 * 3, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "net_softmax = NeuralNetClassifier(NetSoftmax, max_epochs=250, lr=0.01, criterion=torch.nn.CrossEntropyLoss, verbose=0)\n",
    "net_softmax.fit(X_train_flatten, y_train)\n",
    "\n",
    "y_predict = net_softmax.predict(X_test_flatten)\n",
    "\n",
    "print(classification_report(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "pretty-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        X = Image.fromarray(np.uint8(X)).convert('RGB')\n",
    "        X = self.transform(X)\n",
    "        return X, y\n",
    "\n",
    "dataset = CustomDataset(X_train, y_train)\n",
    "dataset_test = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "collect-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 3, output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc1 = torch.nn.Linear(18 * 32 * 32, 64)\n",
    "        \n",
    "        #64 input features, 10 output features for our 10 defined classes\n",
    "        self.fc2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        #Size changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Size changes from (18, 32, 32) to (18, 16, 16)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #Reshape data to input to the input layer of the neural net\n",
    "        #Size changes from (18, 16, 16) to (1, 4608)\n",
    "        #Recall that the -1 infers this dimension from the other given dimension\n",
    "        x = x.view(-1, 18 * 32 * 32)\n",
    "        \n",
    "        #Computes the activation of the first fully connected layer\n",
    "        #Size changes from (1, 4608) to (1, 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "         \n",
    "        #Computes the second fully connected layer (activation applied later)\n",
    "        #Size changes from (1, 64) to (1, 10)\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "valued-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6877\u001b[0m  0.6990\n",
      "      2        \u001b[36m0.9874\u001b[0m  0.8366\n",
      "      3        \u001b[36m0.7514\u001b[0m  0.9216\n",
      "      4        \u001b[36m0.6531\u001b[0m  0.8181\n",
      "      5        \u001b[36m0.5872\u001b[0m  0.8253\n",
      "      6        0.6048  0.8675\n",
      "      7        0.5970  0.8285\n",
      "      8        \u001b[36m0.5610\u001b[0m  0.8083\n",
      "      9        \u001b[36m0.5316\u001b[0m  0.9484\n",
      "     10        \u001b[36m0.5272\u001b[0m  1.0702\n",
      "     11        0.5308  1.1411\n",
      "     12        \u001b[36m0.5117\u001b[0m  1.2366\n",
      "     13        \u001b[36m0.4906\u001b[0m  0.8384\n",
      "     14        \u001b[36m0.4780\u001b[0m  0.9252\n",
      "     15        \u001b[36m0.4708\u001b[0m  1.0266\n",
      "     16        \u001b[36m0.4553\u001b[0m  0.9583\n",
      "     17        \u001b[36m0.4367\u001b[0m  0.7969\n",
      "     18        \u001b[36m0.4241\u001b[0m  0.7519\n",
      "     19        \u001b[36m0.4144\u001b[0m  1.0092\n",
      "     20        \u001b[36m0.4012\u001b[0m  1.0828\n",
      "     21        \u001b[36m0.3878\u001b[0m  1.0565\n",
      "     22        \u001b[36m0.3756\u001b[0m  0.8025\n",
      "     23        \u001b[36m0.3626\u001b[0m  0.9251\n",
      "     24        \u001b[36m0.3517\u001b[0m  1.3072\n",
      "     25        \u001b[36m0.3451\u001b[0m  1.2478\n",
      "     26        \u001b[36m0.3334\u001b[0m  1.1201\n",
      "     27        \u001b[36m0.3218\u001b[0m  1.0272\n",
      "     28        \u001b[36m0.3124\u001b[0m  0.9361\n",
      "     29        \u001b[36m0.3014\u001b[0m  0.9116\n",
      "     30        \u001b[36m0.2922\u001b[0m  0.8590\n",
      "     31        \u001b[36m0.2838\u001b[0m  0.8176\n",
      "     32        \u001b[36m0.2793\u001b[0m  0.8400\n",
      "     33        \u001b[36m0.2664\u001b[0m  0.8845\n",
      "     34        \u001b[36m0.2566\u001b[0m  0.8355\n",
      "     35        \u001b[36m0.2514\u001b[0m  0.8706\n",
      "     36        \u001b[36m0.2418\u001b[0m  0.8402\n",
      "     37        \u001b[36m0.2325\u001b[0m  0.8310\n",
      "     38        \u001b[36m0.2241\u001b[0m  0.8400\n",
      "     39        \u001b[36m0.2113\u001b[0m  0.8494\n",
      "     40        \u001b[36m0.2054\u001b[0m  0.8417\n",
      "     41        0.2107  0.9365\n",
      "     42        \u001b[36m0.1964\u001b[0m  0.8601\n",
      "     43        \u001b[36m0.1841\u001b[0m  0.8228\n",
      "     44        \u001b[36m0.1829\u001b[0m  0.8403\n",
      "     45        \u001b[36m0.1789\u001b[0m  0.8531\n",
      "     46        \u001b[36m0.1677\u001b[0m  0.9624\n",
      "     47        \u001b[36m0.1666\u001b[0m  1.1528\n",
      "     48        \u001b[36m0.1596\u001b[0m  1.0098\n",
      "     49        \u001b[36m0.1480\u001b[0m  0.9204\n",
      "     50        0.1506  0.8644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.64      0.76        25\n",
      "           1       0.73      0.96      0.83        25\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.83      0.80      0.79        50\n",
      "weighted avg       0.83      0.80      0.79        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net_cnn = NeuralNetClassifier(\n",
    "    SimpleCNN,\n",
    "    max_epochs=50,\n",
    "    lr=0.001,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    train_split=None,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "net_cnn.fit(dataset, y_train)\n",
    "y_predict = net_cnn.predict(dataset_test)\n",
    "print(classification_report(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-restoration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
